{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Лабораторная работа №4: Подготовка данных для классификации с использованием случайного леса"],"metadata":{"id":"Ge8FrJbjz9Hn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qt9iPbUVnRSM"},"outputs":[],"source":["import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","\n","\n","# Загрузка данных для классификации\n","# Читаем CSV файл с текстовыми данными (job_title) и метками классов (category).\n","classification_data = pd.read_csv(\"/content/drive/MyDrive/AIMAI/ds1.csv.csv\")\n","\n","# Предварительная обработка данных\n","# Удаляем строки с пропущенными значениями, чтобы избежать ошибок при обработке текста.\n","classification_data = classification_data.dropna()\n","\n","# Разделение на признаки и целевую переменную\n","# X_text: текстовые данные (job_title), которые будем преобразовывать в числовую форму.\n","# y_class: метки классов (category), которые будем использовать как целевую переменную.\n","X_text = classification_data['job_title']\n","y_class = classification_data['category']\n","\n","# Преобразование текстовых данных в числовую форму\n","# Используем метод Bag of Words (CountVectorizer), чтобы представить текст как числовую матрицу.\n","vectorizer = CountVectorizer()\n","X_class = vectorizer.fit_transform(X_text)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","# Тренировочная выборка (80%): используется для обучения модели.\n","# Тестовая выборка (20%): используется для проверки качества модели.\n","# random_state=42 фиксирует случайное состояние для воспроизводимости.\n","X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n","    X_class, y_class, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","source":["# Загрузка данных для задачи регрессии\n","# Читаем CSV файл, содержащий признаки и целевую переменную (price).\n","regression_data = pd.read_csv(\"/content/drive/MyDrive/AIMAI/ds2.csv\")\n","\n","# Разделение данных на признаки и целевую переменную\n","# X_reg: все признаки, кроме целевой переменной (price), адреса (Address) и описания (desc).\n","# y_reg: целевая переменная (price), которую мы будем предсказывать.\n","X_reg = regression_data.drop(columns=[\"price\", \"Address\", \"desc\"])\n","y_reg = regression_data[\"price\"]\n","\n","# Преобразование категориальных данных в числовые\n","# Преобразуем категориальные признаки в числовые с использованием метода one-hot encoding.\n","# drop_first=True исключает первый уровень категорий, чтобы избежать мультиколлинеарности.\n","X_reg = pd.get_dummies(X_reg, drop_first=True)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","# Тренировочная выборка (80%): используется для обучения модели.\n","# Тестовая выборка (20%): используется для проверки качества модели.\n","# random_state=42 фиксирует случайное состояние для воспроизводимости результатов.\n","X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n","    X_reg, y_reg, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"akXrCffY-YNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Модель случайного леса для классификации\n","# random_state=42 фиксирует случайное состояние для воспроизводимости результатов.\n","clf = RandomForestClassifier(random_state=42)\n","\n","# Обучение модели случайного леса на тренировочных данных\n","# X_train_class: матрица признаков для обучения.\n","# y_train_class: метки классов для обучения.\n","clf.fit(X_train_class, y_train_class)\n","\n","# Предсказание классов для тестовых данных\n","# X_test_class: матрица признаков для тестовой выборки.\n","y_pred_class = clf.predict(X_test_class)\n","\n","# Оценка качества модели для задачи классификации\n","print(\"=== Классификация: Бейзлайн ===\")\n","\n","# Accuracy: доля правильно классифицированных объектов.\n","print(\"Accuracy:\", accuracy_score(y_test_class, y_pred_class))\n","\n","# Отчет о классификации\n","# Включает метрики:\n","# - precision: точность предсказания для каждого класса.\n","# - recall: полнота предсказания для каждого класса.\n","# - f1-score: гармоническое среднее precision и recall.\n","# - support: количество объектов каждого класса в тестовой выборке.\n","print(classification_report(y_test_class, y_pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4iMWa0t-yTG","outputId":"6f7a5f8e-5a16-441d-8ba6-05647c2f6995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Классификация: Бейзлайн ===\n","Accuracy: 0.8058856819468024\n","                                        precision    recall  f1-score   support\n","\n","                            Accounting       0.40      0.22      0.29         9\n","       Administration & Office Support       0.81      0.85      0.83       436\n","             Advertising, Arts & Media       0.00      0.00      0.00        12\n","          Banking & Financial Services       0.69      0.76      0.72       208\n","              CEO & General Management       0.67      0.60      0.63        10\n","        Call Centre & Customer Service       0.55      0.51      0.53        35\n","                          Construction       0.76      0.76      0.76        85\n","                 Consulting & Strategy       0.35      0.25      0.29        24\n","                 Design & Architecture       0.80      0.47      0.59        17\n","                           Engineering       0.50      0.33      0.40         3\n","                  Healthcare & Medical       0.00      0.00      0.00         3\n","         Human Resources & Recruitment       0.93      0.92      0.92       366\n","Information & Communication Technology       0.89      0.96      0.92       149\n","            Insurance & Superannuation       0.00      0.00      0.00         1\n","                                 Legal       0.76      0.76      0.76        25\n","  Manufacturing, Transport & Logistics       0.88      0.92      0.90       165\n","            Marketing & Communications       0.72      0.72      0.72        81\n","                Real Estate & Property       0.00      0.00      0.00         2\n","            Retail & Consumer Products       0.83      0.36      0.50        14\n","                                 Sales       0.69      0.66      0.67       116\n","                  Science & Technology       1.00      0.20      0.33         5\n","                     Trades & Services       0.00      0.00      0.00         1\n","\n","                              accuracy                           0.81      1767\n","                             macro avg       0.56      0.47      0.49      1767\n","                          weighted avg       0.79      0.81      0.80      1767\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Модель случайного леса для регрессии\n","# random_state=42 фиксирует случайное состояние для воспроизводимости результатов.\n","reg = RandomForestRegressor(random_state=42)\n","\n","# Обучение модели случайного леса на тренировочных данных\n","# X_train_reg: матрица признаков для обучения.\n","# y_train_reg: целевая переменная для обучения.\n","reg.fit(X_train_reg, y_train_reg)\n","\n","# Предсказание значений для тестовых данных\n","# X_test_reg: матрица признаков для тестовой выборки.\n","y_pred_reg = reg.predict(X_test_reg)\n","\n","# Оценка качества модели для задачи регрессии\n","print(\"\\n=== Регрессия: Бейзлайн ===\")\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка.\n","# Указывает на среднее значение квадрата разницы между предсказанными и реальными значениями.\n","print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n","\n","# R² (R2 Score): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных (значение от 0 до 1, где 1 - идеально).\n","print(\"R2 Score:\", r2_score(y_test_reg, y_pred_reg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CW8JgtvU-4SF","outputId":"3834b8d3-d808-43d5-f45a-906ea7ec8e2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Регрессия: Бейзлайн ===\n","MSE: 408716011860.4651\n","R2 Score: 0.993105759643903\n"]}]},{"cell_type":"code","source":["# Формулирование гипотез для улучшения производительности модели:\n","# Подбор гиперпараметров для случайного леса.\n","# Основные гиперпараметры:\n","# - n_estimators: количество деревьев в лесу.\n","# - max_depth: максимальная глубина каждого дерева (ограничение сложности модели).\n","# - min_samples_split: минимальное количество объектов, необходимое для разделения узла.\n","\n","# Гиперпараметры для задачи классификации\n","param_grid_clf = {\n","    'n_estimators': [50, 100, 150],      # Количество деревьев: от 50 до 150.\n","    'max_depth': [10, 20, None],         # Максимальная глубина: ограничение в 10, 20 или без ограничения.\n","    'min_samples_split': [2, 5, 10]      # Минимальное количество объектов для разделения узла.\n","}\n","\n","# Гиперпараметры для задачи регрессии\n","param_grid_reg = {\n","    'n_estimators': [50, 100, 150],      # Количество деревьев: от 50 до 150.\n","    'max_depth': [10, 20, None],         # Максимальная глубина: ограничение в 10, 20 или без ограничения.\n","    'min_samples_split': [2, 5, 10]      # Минимальное количество объектов для разделения узла.\n","}"],"metadata":{"id":"I6Gt4Al-_NQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Классификация с использованием случайного леса и подбором гиперпараметров\n","# GridSearchCV: поиск лучших параметров с помощью перебора.\n","# - RandomForestClassifier: модель случайного леса для классификации.\n","# - param_grid_clf: сетка гиперпараметров, определённая ранее.\n","# - cv=3: трёхкратная кросс-валидация.\n","# - scoring='accuracy': используем точность как метрику оценки качества модели.\n","grid_clf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_clf, cv=3, scoring='accuracy')\n","\n","# Обучение модели с подбором гиперпараметров\n","# Обучаем GridSearchCV на тренировочных данных (X_train_class, y_train_class).\n","grid_clf.fit(X_train_class, y_train_class)\n","\n","# Лучшая модель (с подобранными гиперпараметрами)\n","best_clf = grid_clf.best_estimator_\n","\n","# Предсказание классов для тестовой выборки\n","y_pred_class_tuned = best_clf.predict(X_test_class)\n","\n","# Оценка качества модели после подбора гиперпараметров\n","print(\"\\n=== Классификация: Улучшенный бейзлайн ===\")\n","\n","# Лучшие параметры модели\n","print(\"Лучшие параметры:\", grid_clf.best_params_)\n","\n","# Точность (Accuracy): доля правильно предсказанных объектов.\n","print(\"Accuracy:\", accuracy_score(y_test_class, y_pred_class_tuned))\n","\n","# Отчёт о классификации\n","# Включает precision, recall, f1-score и support для каждого класса.\n","print(classification_report(y_test_class, y_pred_class_tuned))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haGCw52M_PmX","outputId":"74b13906-74ea-4d3e-dce1-b69c2df73ab2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Классификация: Улучшенный бейзлайн ===\n","Лучшие параметры: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 150}\n","Accuracy: 0.8126768534238823\n","                                        precision    recall  f1-score   support\n","\n","                            Accounting       0.67      0.22      0.33         9\n","       Administration & Office Support       0.80      0.87      0.83       436\n","             Advertising, Arts & Media       0.00      0.00      0.00        12\n","          Banking & Financial Services       0.71      0.77      0.74       208\n","              CEO & General Management       0.56      0.50      0.53        10\n","        Call Centre & Customer Service       0.54      0.57      0.56        35\n","                          Construction       0.78      0.78      0.78        85\n","                 Consulting & Strategy       0.29      0.17      0.21        24\n","                 Design & Architecture       0.83      0.59      0.69        17\n","                           Engineering       0.50      0.33      0.40         3\n","                  Healthcare & Medical       0.00      0.00      0.00         3\n","         Human Resources & Recruitment       0.93      0.93      0.93       366\n","Information & Communication Technology       0.87      0.97      0.92       149\n","            Insurance & Superannuation       0.00      0.00      0.00         1\n","                                 Legal       0.78      0.72      0.75        25\n","  Manufacturing, Transport & Logistics       0.88      0.90      0.89       165\n","            Marketing & Communications       0.81      0.68      0.74        81\n","                Real Estate & Property       0.00      0.00      0.00         2\n","            Retail & Consumer Products       0.83      0.36      0.50        14\n","                                 Sales       0.75      0.64      0.69       116\n","                  Science & Technology       1.00      0.20      0.33         5\n","                     Trades & Services       0.00      0.00      0.00         1\n","\n","                              accuracy                           0.81      1767\n","                             macro avg       0.57      0.46      0.49      1767\n","                          weighted avg       0.80      0.81      0.80      1767\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","# Регрессия с использованием случайного леса и случайного поиска гиперпараметров\n","# RandomizedSearchCV: выполняет случайный поиск по сетке гиперпараметров.\n","# - RandomForestRegressor: модель случайного леса для регрессии.\n","# - param_distributions=param_grid_reg: сетка гиперпараметров.\n","# - n_iter=5: количество случайных комбинаций для проверки (уменьшает вычислительную нагрузку).\n","# - cv=3: трёхкратная кросс-валидация.\n","# - scoring='r2': используем коэффициент детерминации (R²) как метрику оценки.\n","# - n_jobs=-1: используем все доступные ядра процессора для ускорения.\n","random_reg = RandomizedSearchCV(\n","    RandomForestRegressor(random_state=42),\n","    param_distributions=param_grid_reg,\n","    n_iter=5,  # Проверяем 5 случайных комбинаций\n","    cv=3,\n","    scoring='r2',  # Метрика R² для оценки качества\n","    n_jobs=-1,\n","    random_state=42\n",")\n","\n","# Обучение модели с подбором гиперпараметров\n","# RandomizedSearchCV обучается на тренировочных данных (X_train_reg, y_train_reg).\n","random_reg.fit(X_train_reg, y_train_reg)\n","\n","# Лучшая модель (с подобранными гиперпараметрами)\n","best_reg = random_reg.best_estimator_\n","\n","# Предсказание значений целевой переменной для тестовой выборки\n","y_pred_reg_tuned = best_reg.predict(X_test_reg)\n","\n","# Оценка качества модели после подбора гиперпараметров\n","print(\"\\n=== Регрессия: Улучшенный бейзлайн ===\")\n","\n","# Лучшие параметры модели\n","print(\"Лучшие параметры:\", random_reg.best_params_)\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка предсказаний.\n","print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg_tuned))\n","\n","# R² (R2 Score): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных.\n","print(\"R2 Score:\", r2_score(y_test_reg, y_pred_reg_tuned))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bvz0z0FoADKF","outputId":"92bb99da-1c06-4d24-dbf4-29a02431044b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Регрессия: Улучшенный бейзлайн с RandomizedSearch ===\n","Лучшие параметры: {'n_estimators': 100, 'min_samples_split': 5, 'max_depth': 20}\n","MSE: 497947779992.0194\n","R2 Score: 0.9916005941034142\n"]}]},{"cell_type":"code","source":["def manual_random_forest(X, y, n_estimators=10, max_depth=None):\n","    \"\"\"\n","    Реализация простого случайного леса вручную, основанного на решающих деревьях.\n","\n","    Параметры:\n","    - X: матрица признаков (NumPy массив).\n","    - y: вектор целевой переменной (строки для классификации или числа для регрессии).\n","    - n_estimators: количество деревьев в лесу (по умолчанию 10).\n","    - max_depth: максимальная глубина каждого дерева (по умолчанию None - без ограничения).\n","\n","    Возвращает:\n","    - Список обученных деревьев.\n","    \"\"\"\n","    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","\n","    trees = []  # Список для хранения деревьев\n","    for _ in range(n_estimators):\n","        # Генерация случайной bootstrap-выборки\n","        # Генерируем индексы с повторением, чтобы создать новую обучающую выборку\n","        bootstrap_indices = np.random.choice(range(len(y)), size=len(y), replace=True)\n","        X_bootstrap = X[bootstrap_indices]  # Признаки для bootstrap-выборки\n","        y_bootstrap = y[bootstrap_indices]  # Целевая переменная для bootstrap-выборки\n","\n","        # Выбор типа дерева (классификатор или регрессор) на основе типа целевой переменной\n","        if isinstance(y[0], str):  # Если целевая переменная строковая\n","            tree = DecisionTreeClassifier(max_depth=max_depth)  # Дерево для классификации\n","        else:\n","            tree = DecisionTreeRegressor(max_depth=max_depth)  # Дерево для регрессии\n","\n","        # Обучение дерева на bootstrap-выборке\n","        tree.fit(X_bootstrap, y_bootstrap)\n","        trees.append(tree)  # Сохраняем обученное дерево\n","\n","    return trees"],"metadata":{"id":"DsIdXmQOCth1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Создание отображения классов в числовые метки\n","# Генерируем словарь, который сопоставляет каждому классу (label) числовой индекс (idx).\n","class_mapping = {label: idx for idx, label in enumerate(np.unique(y_train_class))}\n","\n","# Обратное отображение для преобразования предсказаний обратно в исходные метки классов.\n","inv_class_mapping = {idx: label for label, idx in class_mapping.items()}\n","\n","# Преобразуем тренировочные метки классов в числовые значения с использованием отображения.\n","y_train_class_num = np.array([class_mapping[label] for label in y_train_class])\n","\n","# Обучение самописного случайного леса для задачи классификации\n","# Используем массив признаков (X_train_class.toarray()) и числовые метки классов (y_train_class_num).\n","# Параметры:\n","# - n_estimators=10: количество деревьев в лесу.\n","# - max_depth=10: ограничение глубины каждого дерева.\n","manual_forest_class = manual_random_forest(X_train_class.toarray(), y_train_class_num, n_estimators=10, max_depth=10)\n","\n","# Прогнозирование на тестовых данных\n","# Получаем предсказания от каждого дерева (в виде числовых меток классов).\n","# Преобразуем разреженную матрицу признаков (X_test_class) в плотную с помощью .toarray().\n","manual_preds_class = np.mean([tree.predict(X_test_class.toarray()) for tree in manual_forest_class], axis=0)\n","\n","# Преобразуем средние предсказания (числовые) в исходные метки классов.\n","# Используем округление до ближайшего целого для числовых предсказаний.\n","man_pred_class_labels = [inv_class_mapping[int(round(pred))] for pred in manual_preds_class]\n","\n","# Оценка качества самописного случайного леса для классификации\n","print(\"\\n=== Классификация: Самописный случайный лес ===\")\n","\n","# Accuracy: доля правильно классифицированных объектов.\n","print(\"Accuracy:\", accuracy_score(y_test_class, man_pred_class_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlpHE4nSGl13","outputId":"1f857ed4-4be3-4b40-a772-b38ae876dce1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Классификация: Самописный случайный лес ===\n","Accuracy: 0.3503112620260328\n"]}]},{"cell_type":"code","source":["# Обучение самописного случайного леса для задачи регрессии\n","# Используем данные в формате NumPy массивов (X_train_reg, y_train_reg).\n","# Параметры:\n","# - n_estimators=10: количество деревьев в лесу.\n","# - max_depth=10: ограничение глубины каждого дерева.\n","manual_forest_reg = manual_random_forest(X_train_reg.to_numpy(), y_train_reg.to_numpy(), n_estimators=10, max_depth=10)\n","\n","# Прогнозирование на тестовых данных\n","# Получаем предсказания от каждого дерева для всех объектов тестовой выборки.\n","# Предсказания усредняются (аналог усреднения в ансамблях для регрессии).\n","manual_preds_reg = np.mean([tree.predict(X_test_reg.to_numpy()) for tree in manual_forest_reg], axis=0)\n","\n","# Оценка качества самописного случайного леса для регрессии\n","print(\"\\n=== Регрессия: Самописный случайный лес ===\")\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка предсказаний.\n","# Показывает среднее значение квадрата разницы между предсказанными и реальными значениями.\n","print(\"MSE:\", mean_squared_error(y_test_reg, manual_preds_reg))\n","\n","# R² (R2 Score): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных (чем ближе к 1, тем лучше).\n","print(\"R2 Score:\", r2_score(y_test_reg, manual_preds_reg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8kB02rDHNZg","outputId":"76197c9d-652e-4bb2-c4f7-b16ca1760c04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Регрессия: Самописный случайный лес ===\n","MSE: 494091588682.0969\n","R2 Score: 0.9916656405145607\n"]}]},{"cell_type":"markdown","source":["# Общие выводы:\n","\t•\tСлучайный лес является эффективным алгоритмом для работы с разнородными данными.\n","\t•\tБиблиотечные реализации превосходят самописные по производительности, но создание собственной версии позволило глубже понять внутренние механизмы алгоритма.\n","\t•\tУлучшение гиперпараметров через GridSearchCV и RandomizedSearchCV увеличивает точность и надёжность моделей.\n"],"metadata":{"id":"F-qY7ts604iw"}}]}