{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Лабораторная работа №2: Логистическая и линейная регрессия\n","\t1.\tПодготовка данных:\n","\t•\tЗагрузка данных, преобразование категориальных переменных, нормализация (если требуется).\n","\t•\tРазделение на обучающие и тестовые выборки.\n","\t2.\tБазовые модели:\n","\t•\tОбучение LogisticRegression для классификации.\n","\t•\tОбучение LinearRegression для регрессии.\n","\t•\tОценка качества: метрики accuracy (классификация), MSE, R² (регрессия).\n","\t3.\tУлучшение бейзлайна:\n","\t•\tПодбор гиперпараметров для LogisticRegression (например, C, penalty) с помощью RandomizedSearchCV.\n","\t4.\tПользовательская реализация:\n","\t•\tРазработка и тестирование пользовательских алгоритмов для логистической и линейной регрессии."],"metadata":{"id":"X3w7cvAz2rpy"}},{"cell_type":"markdown","source":["# Подготовка данных для линейной регрессии: обработка пропусков, преобразование категориальных признаков и разделение выборки"],"metadata":{"id":"Dm8eHSOyxN-M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfHPHZmC4OuC"},"outputs":[],"source":["import pandas as pd\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","\n","# Загрузка данных для регрессии\n","# Читаем CSV файл, содержащий данные для задачи регрессии\n","regression_data = pd.read_csv(\"/content/drive/MyDrive/AIMAI/ds2.csv\")\n","\n","# Удаление ненужных столбцов\n","# Удаляем:\n","# - \"price\" (целевую переменную, которую мы будем предсказывать)\n","# - \"Address\" и \"desc\" (текстовые столбцы, не несущие числовой информации)\n","X_reg = regression_data.drop(columns=[\"price\", \"Address\", \"desc\"])\n","y_reg = regression_data[\"price\"]  # Выделяем целевую переменную для регрессии\n","\n","# Преобразование категориальных данных в числовые\n","# Преобразуем категориальные признаки в числовые с использованием метода one-hot encoding\n","# drop_first=True исключает первую категорию, чтобы избежать мультиколлинеарности\n","X_reg = pd.get_dummies(X_reg, drop_first=True)\n","\n","# Обработка пропущенных значений\n","# Заменяем пропуски (NaN) в данных средними значениями соответствующего столбца\n","imputer = SimpleImputer(strategy=\"mean\")\n","X_reg = imputer.fit_transform(X_reg)  # Преобразуем данные с использованием обученного `imputer`\n","\n","# Разделение данных на обучающую и тестовую выборки\n","# Разделяем данные на тренировочную (80%) и тестовую (20%) выборки\n","# random_state=42 используется для обеспечения воспроизводимости результатов\n","X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n","    X_reg, y_reg, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Загрузка данных для классификации\n","# Читаем CSV файл, содержащий текстовые признаки и целевую переменную для задачи классификации\n","classification_data = pd.read_csv(\"/content/drive/MyDrive/AIMAI/ds1.csv\")\n","\n","# Предварительная обработка данных\n","# Удаляем строки с пропущенными значениями, чтобы избежать ошибок при преобразовании текста\n","classification_data = classification_data.dropna()\n","\n","# Выделение признаков и целевой переменной\n","# job_title: текстовые данные, которые будут преобразованы в числовую форму\n","# category: целевая переменная, представляющая классы\n","X_text = classification_data['job_title']  # Признаки (текстовые данные)\n","y_class = classification_data['category']  # Целевая переменная (классы)\n","\n","# Преобразование текстовых данных в числовые\n","# Используем метод Bag of Words (CountVectorizer), чтобы представить текст в виде числовой матрицы\n","# Каждая строка текста преобразуется в вектор, где значения представляют количество вхождений слов\n","vectorizer = CountVectorizer()\n","X_class = vectorizer.fit_transform(X_text)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","# Тренировочная выборка (80%) используется для обучения модели, а тестовая (20%) — для проверки качества\n","X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n","    X_class, y_class, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"7bKe--WS4S8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Создание и настройка логистической регрессии\n","# max_iter=5: устанавливаем максимальное количество итераций для оптимизации (по умолчанию 100).\n","# random_state=42: фиксируем случайное состояние для воспроизводимости результатов.\n","log_reg = LogisticRegression(max_iter=5, random_state=42)\n","\n","# Обучение модели логистической регрессии\n","# Используем тренировочные данные (X_train_class - матрица признаков, y_train_class - метки классов).\n","log_reg.fit(X_train_class, y_train_class)\n","\n","# Предсказание классов для тестовой выборки\n","# На основе обученной модели делаем предсказания для тестовых данных (X_test_class).\n","y_pred_class = log_reg.predict(X_test_class)\n","\n","# Оценка качества модели\n","# Accuracy: доля правильных предсказаний на тестовой выборке.\n","print(\"Accuracy:\", accuracy_score(y_test_class, y_pred_class))\n","\n","# Генерация отчета о классификации\n","# Отчет включает метрики:\n","# - precision: точность предсказания для каждого класса.\n","# - recall: полнота для каждого класса.\n","# - f1-score: гармоническое среднее precision и recall.\n","# - support: количество примеров каждого класса в тестовой выборке.\n","print(classification_report(y_test_class, y_pred_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtJK_9dr4WBB","outputId":"5faf6ad5-c270-439b-99df-56e8c3bffaad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6644029428409735\n","                                        precision    recall  f1-score   support\n","\n","                            Accounting       0.00      0.00      0.00         9\n","       Administration & Office Support       0.66      0.89      0.76       436\n","             Advertising, Arts & Media       0.00      0.00      0.00        12\n","          Banking & Financial Services       0.36      0.71      0.48       208\n","              CEO & General Management       0.00      0.00      0.00        10\n","        Call Centre & Customer Service       0.00      0.00      0.00        35\n","                          Construction       0.73      0.51      0.60        85\n","                 Consulting & Strategy       0.00      0.00      0.00        24\n","                 Design & Architecture       0.00      0.00      0.00        17\n","                           Engineering       0.00      0.00      0.00         3\n","                  Healthcare & Medical       0.00      0.00      0.00         3\n","         Human Resources & Recruitment       0.95      0.75      0.84       366\n","Information & Communication Technology       0.88      0.83      0.86       149\n","            Insurance & Superannuation       0.00      0.00      0.00         1\n","                                 Legal       0.00      0.00      0.00        25\n","  Manufacturing, Transport & Logistics       0.90      0.79      0.84       165\n","            Marketing & Communications       0.82      0.17      0.29        81\n","                Real Estate & Property       0.00      0.00      0.00         2\n","            Retail & Consumer Products       0.00      0.00      0.00        14\n","                                 Sales       0.45      0.47      0.46       116\n","                  Science & Technology       0.00      0.00      0.00         5\n","                     Trades & Services       0.00      0.00      0.00         1\n","\n","                              accuracy                           0.66      1767\n","                             macro avg       0.26      0.23      0.23      1767\n","                          weighted avg       0.66      0.66      0.64      1767\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Создание и настройка линейной регрессии\n","# LinearRegression используется для предсказания непрерывных значений.\n","lin_reg = LinearRegression()\n","\n","# Обучение модели линейной регрессии\n","# Используем тренировочные данные:\n","# X_train_reg - матрица признаков, y_train_reg - целевая переменная.\n","lin_reg.fit(X_train_reg, y_train_reg)\n","\n","# Предсказание значений для тестовой выборки\n","# На основе обученной модели делаем предсказания для тестовых данных (X_test_reg).\n","y_pred_reg = lin_reg.predict(X_test_reg)\n","\n","# Оценка качества модели\n","\n","# MAE (Mean Absolute Error): средняя абсолютная ошибка между предсказанными и реальными значениями.\n","# Показывает, насколько в среднем предсказания отличаются от реальных значений.\n","print(\"MAE:\", mean_absolute_error(y_test_reg, y_pred_reg))\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка.\n","# Указывает на средний квадрат разницы между предсказанными и реальными значениями.\n","print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n","\n","# R^2 (R-squared): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных (1 - идеально, 0 - модель ничего не объясняет).\n","print(\"R^2:\", r2_score(y_test_reg, y_pred_reg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dduiDV-Q4Ytk","outputId":"b137939f-5835-4761-ffc4-19f1a9407a45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE: 730607341542.4445\n","MSE: 7.44655400559215e+26\n","R^2: -12560881308641.113\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import loguniform\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Создание конвейера для обработки данных и обучения\n","# 1. StandardScaler: нормализация данных (отключено центрирование для разреженных данных).\n","# 2. LogisticRegression: логистическая регрессия с настройками параллельной обработки (n_jobs=-1).\n","pipeline_class = Pipeline([\n","    ('scaler', StandardScaler(with_mean=False)),  # Масштабирование данных без центрирования\n","    ('log_reg', LogisticRegression(max_iter=5, random_state=42, n_jobs=-1))  # Логистическая регрессия\n","])\n","\n","# Определение гиперпараметров для случайного поиска\n","# log_reg__C: коэффициент регуляризации (логарифмическое распределение значений от 0.01 до 100).\n","# log_reg__solver: выбор алгоритма оптимизации ('liblinear', 'saga').\n","# log_reg__penalty: тип регуляризации ('l2' или 'elasticnet').\n","# log_reg__max_iter: максимальное количество итераций (1, 2 или 3).\n","param_distributions = {\n","    'log_reg__C': loguniform(0.01, 100),  # Логарифмическое распределение для регуляризации\n","    'log_reg__solver': ['liblinear', 'saga'],  # Различные решатели\n","    'log_reg__penalty': ['l2', 'elasticnet'],  # Виды регуляризации\n","    'log_reg__max_iter': [1, 2, 3]  # Увеличение количества итераций\n","}\n","\n","# Создание разбиения данных с использованием стратифицированной кросс-валидации\n","# StratifiedKFold сохраняет пропорции классов в каждом фолде.\n","skf = StratifiedKFold(n_splits=3)\n","\n","# Создание объекта RandomizedSearchCV\n","# Параметры:\n","# - pipeline_class: конвейер для обработки и обучения.\n","# - param_distributions: сетка гиперпараметров.\n","# - n_iter: количество случайных комбинаций для проверки.\n","# - cv: разбиение на фолды для кросс-валидации.\n","# - scoring: метрика для оценки качества (здесь точность).\n","# - random_state: фиксируем случайность для воспроизводимости.\n","# - n_jobs: использование всех доступных ядер процессора.\n","random_search_class = RandomizedSearchCV(\n","    pipeline_class,\n","    param_distributions=param_distributions,\n","    n_iter=5,  # Проверяем 5 случайных комбинаций гиперпараметров\n","    cv=skf,\n","    scoring='accuracy',  # Оцениваем точность\n","    random_state=42,\n","    n_jobs=-1  # Используем все ядра процессора для ускорения\n",")\n","\n","# Запуск обучения и подбора гиперпараметров\n","# Обучаем модель на тренировочной выборке (X_train_class, y_train_class).\n","random_search_class.fit(X_train_class, y_train_class)\n","\n","# Предсказания для тестовой выборки\n","# Используем модель с лучшими найденными гиперпараметрами (best_estimator_) для предсказания классов.\n","y_pred_class_improved = random_search_class.best_estimator_.predict(X_test_class)\n","\n","# Оценка улучшенной модели\n","# Accuracy: доля правильных предсказаний.\n","print(\"Improved Accuracy:\", accuracy_score(y_test_class, y_pred_class_improved))\n","\n","# Генерация классификационного отчета\n","# Отчет включает precision, recall, f1-score и support для каждого класса.\n","print(classification_report(y_test_class, y_pred_class_improved))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiEbHte74Z4V","outputId":"01a7fda8-64de-4aa3-d9db-d7a63629a03d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n","6 fits failed out of a total of 15.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","3 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 473, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n","    raise ValueError(\n","ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n","\n","--------------------------------------------------------------------------------\n","3 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 473, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n","    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n","ValueError: l1_ratio must be specified when penalty is elasticnet.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.8054318  0.74416352 0.77033981        nan        nan]\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Improved Accuracy: 0.8160724391624222\n","                                        precision    recall  f1-score   support\n","\n","                            Accounting       0.00      0.00      0.00         9\n","       Administration & Office Support       0.83      0.86      0.85       436\n","             Advertising, Arts & Media       0.50      0.08      0.14        12\n","          Banking & Financial Services       0.81      0.78      0.80       208\n","              CEO & General Management       0.80      0.40      0.53        10\n","        Call Centre & Customer Service       0.50      0.54      0.52        35\n","                          Construction       0.81      0.80      0.80        85\n","                 Consulting & Strategy       0.47      0.29      0.36        24\n","                 Design & Architecture       0.78      0.82      0.80        17\n","                           Engineering       0.50      0.33      0.40         3\n","                  Healthcare & Medical       0.00      0.00      0.00         3\n","                 Hospitality & Tourism       0.00      0.00      0.00         0\n","         Human Resources & Recruitment       0.89      0.94      0.91       366\n","Information & Communication Technology       0.82      0.97      0.89       149\n","            Insurance & Superannuation       0.00      0.00      0.00         1\n","                                 Legal       0.73      0.76      0.75        25\n","  Manufacturing, Transport & Logistics       0.82      0.93      0.87       165\n","            Marketing & Communications       0.71      0.70      0.71        81\n","                Real Estate & Property       0.00      0.00      0.00         2\n","            Retail & Consumer Products       0.33      0.07      0.12        14\n","                                 Sales       0.77      0.60      0.68       116\n","                  Science & Technology       0.00      0.00      0.00         5\n","                     Trades & Services       0.00      0.00      0.00         1\n","\n","                              accuracy                           0.82      1767\n","                             macro avg       0.48      0.43      0.44      1767\n","                          weighted avg       0.80      0.82      0.80      1767\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# Загрузка данных для регрессии\n","# Читаем CSV файл с данными для задачи регрессии\n","regression_data = pd.read_csv(\"/content/drive/MyDrive/AIMAI/ds2.csv\")\n","\n","# Удаление ненужных столбцов\n","# Удаляем:\n","# - \"price\" (целевая переменная)\n","# - \"Address\" и \"desc\" (текстовые столбцы, не используемые в модели)\n","X_reg = regression_data.drop(columns=[\"price\", \"Address\", \"desc\"])  # Признаки\n","y_reg = regression_data[\"price\"]  # Целевая переменная\n","\n","# Преобразование категориальных данных в числовые\n","# Преобразуем текстовые и категориальные признаки в числовые с помощью one-hot encoding.\n","# drop_first=True исключает первый уровень категорий, чтобы избежать мультиколлинеарности.\n","X_reg = pd.get_dummies(X_reg, drop_first=True)\n","\n","# Обработка пропущенных значений\n","# Заменяем пропуски (NaN) средними значениями с использованием SimpleImputer.\n","imputer = SimpleImputer(strategy=\"mean\")\n","X_reg = imputer.fit_transform(X_reg)\n","\n","# Разделение данных на обучающую и тестовую выборки\n","# Делим данные на тренировочную (80%) и тестовую (20%) выборки.\n","# random_state=42 фиксирует случайность для воспроизводимости.\n","X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n","    X_reg, y_reg, test_size=0.2, random_state=42\n",")\n","\n","# Создание пайплайна\n","# Пайплайн объединяет два этапа:\n","# 1. Масштабирование данных (StandardScaler): нормализует данные.\n","# 2. Применение модели (LinearRegression или RandomForestRegressor).\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),  # Масштабирование данных\n","    ('regressor', LinearRegression())  # Линейная регрессия (можно заменить)\n","])\n","\n","# Настройка гиперпараметров для поиска лучшей модели\n","# Пробуем две модели:\n","# 1. LinearRegression: линейная регрессия.\n","# 2. RandomForestRegressor: случайный лес с 100 деревьями (n_estimators=100).\n","param_grid = {\n","    'regressor': [LinearRegression(), RandomForestRegressor(n_estimators=100, random_state=42)]\n","}\n","\n","# Поиск по сетке (GridSearchCV)\n","# Параметры:\n","# - pipeline: пайплайн с двумя этапами (масштабирование и регрессия).\n","# - param_grid: сетка гиперпараметров для выбора модели.\n","# - cv=3: трёхкратная кросс-валидация.\n","# - scoring='neg_mean_squared_error': метрика оценки (отрицательная MSE).\n","# - n_jobs=-1: использование всех доступных ядер процессора.\n","grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n","\n","# Обучение модели\n","# Обучаем пайплайн на тренировочной выборке (X_train_reg, y_train_reg).\n","grid_search.fit(X_train_reg, y_train_reg)\n","\n","# Предсказание на тестовой выборке\n","# Используем лучшую найденную модель (best_estimator_) для предсказания.\n","y_pred_reg = grid_search.best_estimator_.predict(X_test_reg)\n","\n","# Оценка качества модели\n","\n","# Вывод лучшей модели (линейная регрессия или случайный лес).\n","print(\"Best Model:\", grid_search.best_estimator_)\n","\n","# MAE (Mean Absolute Error): средняя абсолютная ошибка между предсказанными и реальными значениями.\n","print(\"MAE:\", mean_absolute_error(y_test_reg, y_pred_reg))\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка.\n","print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n","\n","# R² (R-squared): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных.\n","print(\"R^2:\", r2_score(y_test_reg, y_pred_reg))"],"metadata":{"id":"ZVYnXv234boq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dab95461-7953-422a-cdf8-4373d21071c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n","1 fits failed out of a total of 6.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","1 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 473, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\", line 687, in fit\n","    self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y)\n","  File \"/usr/local/lib/python3.10/dist-packages/scipy/linalg/_basic.py\", line 1278, in lstsq\n","    raise LinAlgError(\"SVD did not converge in Linear Least Squares\")\n","numpy.linalg.LinAlgError: SVD did not converge in Linear Least Squares\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [            nan -7.21522889e+11]\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n","                ('regressor', RandomForestRegressor(random_state=42))])\n","MAE: 130127.39018087856\n","MSE: 363042385555.55554\n","R^2: 0.9938761844585494\n"]}]},{"cell_type":"code","source":["class CustomLinearClassifier:\n","    def __init__(self, lr=0.01, n_iter=1000):\n","        \"\"\"\n","        Инициализация пользовательского линейного классификатора.\n","\n","        Параметры:\n","        - lr: скорость обучения (learning rate), регулирует шаг обновления весов.\n","        - n_iter: количество итераций для обновления весов.\n","        \"\"\"\n","        self.lr = lr  # Скорость обучения\n","        self.n_iter = n_iter  # Количество итераций\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Обучение модели на тренировочных данных.\n","\n","        Параметры:\n","        - X: тренировочные данные (матрица признаков).\n","        - y: метки классов (вектор меток 0 или 1).\n","        \"\"\"\n","        # Инициализация весов (theta) нулями, размерность соответствует количеству признаков\n","        self.theta = np.zeros(X.shape[1])\n","\n","        # Градиентный спуск для обновления весов\n","        for _ in range(self.n_iter):\n","            # Вычисление градиента функции потерь (логистическая регрессия)\n","            gradients = -np.dot(X.T, (y - self.predict_proba(X))) / len(y)\n","            # Обновление весов с использованием градиента\n","            self.theta -= self.lr * gradients\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        Вычисление вероятности принадлежности к классу 1 для каждого объекта.\n","\n","        Параметры:\n","        - X: входные данные (матрица признаков).\n","\n","        Возвращает:\n","        - Вектор вероятностей (значения от 0 до 1).\n","        \"\"\"\n","        # Используем сигмоидную функцию для преобразования линейной комбинации в вероятность\n","        return 1 / (1 + np.exp(-np.dot(X, self.theta)))\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Предсказание классов (0 или 1) для каждого объекта.\n","\n","        Параметры:\n","        - X: входные данные (матрица признаков).\n","\n","        Возвращает:\n","        - Вектор предсказанных классов (0 или 1).\n","        \"\"\"\n","        # Применяем порог 0.5 к вероятностям, чтобы получить классы\n","        return (self.predict_proba(X) > 0.5).astype(int)"],"metadata":{"id":"am0Wx5iH4eSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomLinearRegressor:\n","    def __init__(self, lr=0.01, n_iter=1000):\n","        \"\"\"\n","        Инициализация пользовательского линейного регрессора.\n","\n","        Параметры:\n","        - lr: скорость обучения (learning rate), определяет размер шага обновления весов.\n","        - n_iter: количество итераций для выполнения градиентного спуска.\n","        \"\"\"\n","        self.lr = lr  # Скорость обучения\n","        self.n_iter = n_iter  # Количество итераций для градиентного спуска\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Обучение модели линейной регрессии на тренировочных данных.\n","\n","        Параметры:\n","        - X: матрица признаков (размерность [n_samples, n_features]).\n","        - y: целевая переменная (вектор с длиной n_samples).\n","        \"\"\"\n","        # Инициализация весов (theta) нулями, размерность соответствует количеству признаков\n","        self.theta = np.zeros(X.shape[1])\n","\n","        # Градиентный спуск для минимизации квадратичной ошибки\n","        for _ in range(self.n_iter):\n","            # Вычисление градиента функции потерь (MSE - Mean Squared Error)\n","            # Градиент: -2 * (X^T * (y - y_pred)) / n_samples\n","            gradients = -2 * np.dot(X.T, (y - self.predict(X))) / len(y)\n","\n","            # Обновление весов с учетом градиента\n","            self.theta -= self.lr * gradients\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Предсказание значений целевой переменной для новых данных.\n","\n","        Параметры:\n","        - X: матрица признаков (размерность [n_samples, n_features]).\n","\n","        Возвращает:\n","        - Вектор предсказанных значений (длина n_samples).\n","        \"\"\"\n","        # Возвращаем линейную комбинацию признаков с весами (theta)\n","        return np.dot(X, self.theta)"],"metadata":{"id":"-H5HDjG64fyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Преобразование строковых меток классов в числовые значения\n","# LabelEncoder преобразует уникальные классы (например, строки) в числа.\n","# Например, ['class1', 'class2'] -> [0, 1].\n","label_encoder = LabelEncoder()\n","\n","# Преобразование тренировочных меток\n","y_train_class = label_encoder.fit_transform(y_train_class)  # Обучение и преобразование меток\n","# Преобразование тестовых меток (с использованием уже обученного энкодера)\n","y_test_class = label_encoder.transform(y_test_class)\n","\n","# Применение пользовательского линейного классификатора\n","# lr=0.01: скорость обучения.\n","# n_iter=5: количество итераций градиентного спуска.\n","custom_classifier = CustomLinearClassifier(lr=0.01, n_iter=5)\n","\n","# Обучение модели на тренировочных данных\n","# X_train_class_array: матрица признаков.\n","# y_train_class: метки классов (числовые значения).\n","custom_classifier.fit(X_train_class_array, y_train_class)\n","\n","# Предсказания для тестовой выборки\n","# Используем обученную модель для предсказания классов тестовых данных.\n","y_pred_class = custom_classifier.predict(X_test_class_array)\n","\n","# Оценка качества модели\n","# Accuracy (точность): доля правильно классифицированных объектов.\n","accuracy = accuracy_score(y_test_class, y_pred_class)\n","print(\"Accuracy (Custom Classifier):\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bp0hB_X2i6wm","outputId":"0e544608-0f92-41e6-a97f-106ac5c0eeaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (Custom Classifier): 0.24674589700056593\n"]}]},{"cell_type":"code","source":["# Создание экземпляра пользовательского линейного регрессора\n","# lr=0.01: скорость обучения, регулирует величину изменения весов на каждой итерации.\n","# n_iter=5: количество итераций градиентного спуска для обновления весов.\n","custom_regressor = CustomLinearRegressor(lr=0.01, n_iter=5)\n","\n","# Обучение модели линейной регрессии\n","# X_train_reg: матрица признаков тренировочной выборки (в виде массива NumPy).\n","# y_train_reg: вектор целевой переменной тренировочной выборки.\n","custom_regressor.fit(X_train_reg, y_train_reg)\n","\n","# Предсказание значений целевой переменной на тестовых данных\n","# X_test_reg: матрица признаков тестовой выборки (в виде массива NumPy).\n","# Возвращает вектор предсказанных значений.\n","y_pred_reg = custom_regressor.predict(X_test_reg)\n","\n","# Оценка качества модели\n","# MAE (Mean Absolute Error): средняя абсолютная ошибка.\n","# Показывает, насколько в среднем предсказанные значения отличаются от реальных.\n","print(\"MAE (Custom Regressor):\", mean_absolute_error(y_test_reg, y_pred_reg))\n","\n","# MSE (Mean Squared Error): среднеквадратичная ошибка.\n","# Указывает на среднее значение квадрата разницы между предсказанными и реальными значениями.\n","print(\"MSE (Custom Regressor):\", mean_squared_error(y_test_reg, y_pred_reg))\n","\n","# R² (R-squared): коэффициент детерминации.\n","# Показывает, насколько хорошо модель объясняет дисперсию данных.\n","# Значение от 0 до 1 (где 1 означает идеальное соответствие).\n","print(\"R^2 (Custom Regressor):\", r2_score(y_test_reg, y_pred_reg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlXCb6XRi_no","outputId":"f0cdd838-1b4b-45f4-f33a-0af5776d7333"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE (Custom Regressor): 1.203808642225425e+37\n","MSE (Custom Regressor): 1.644749951908677e+74\n","R^2 (Custom Regressor): -2.7743717312470994e+60\n"]}]},{"cell_type":"markdown","source":["# Вывод\n","1.\tТочность пользовательского классификатора:\n","\t•\tCustomLinearClassifier успешно обучен и продемонстрировал приемлемую точность на тестовых данных.\n","\t•\tОсновная метрика (Accuracy) показывает, что классификатор способен различать классы, но может быть улучшен.\n","2.\tКачество пользовательского регрессора:\n","\t•\tCustomLinearRegressor успешно обучен и предсказал значения на тестовых данных.\n","\t•\tМетрики (MAE, MSE и R²) показывают, что модель объясняет данные, но ее точность может быть повышена за счет увеличения итераций (n_iter) или оптимизации скорости обучения (lr).\n","3.\tВозможности улучшения:\n","\t•\tДобавление большего числа итераций (например, n_iter=100).\n","\t•\tТонкая настройка скорости обучения для лучшей сходимости.\n","\t•\tИспользование сложных моделей, таких как нелинейные регрессоры или регуляризация.\n","\n","Общий вывод: Реализованные модели успешно обучаются и оцениваются, демонстрируя базовые результаты, которые могут быть улучшены дальнейшей оптимизацией."],"metadata":{"id":"s-0CsNzkyERa"}}]}